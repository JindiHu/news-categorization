{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "1d0710db248a1797"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T05:07:16.640465Z",
     "start_time": "2025-03-15T05:07:16.636591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import utils"
   ],
   "id": "89c2f1be807309e1",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NewDataset class",
   "id": "5f57987530b82120"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T05:07:16.654967Z",
     "start_time": "2025-03-15T05:07:16.652674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "id": "617861f8a58c9e71",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the NewsClassifier class",
   "id": "3c7b4c9cce47e6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T05:07:16.938526Z",
     "start_time": "2025-03-15T05:07:16.936326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(NewsClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        output = self.drop(outputs.pooler_output)\n",
    "        return self.out(output)\n"
   ],
   "id": "80fb7c61417fbebe",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and preprocess the data",
   "id": "2cbc22fa8d5faf64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T05:07:27.098993Z",
     "start_time": "2025-03-15T05:07:17.229241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_df = utils.load_data_from_directories(articles_dir='./data/news', summaries_dir='./data/summaries')\n",
    "label_encoder = LabelEncoder()\n",
    "data_df['category_encoded'] = label_encoder.fit_transform(data_df['category'])\n",
    "\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "train_texts = train_df['content'].tolist()\n",
    "test_texts = test_df['content'].tolist()\n",
    "train_labels = train_df['category_encoded'].tolist()\n",
    "test_labels = test_df['category_encoded'].tolist()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "train_dataset = NewsDataset(train_encodings, train_labels)\n",
    "test_dataset = NewsDataset(test_encodings, test_labels)\n"
   ],
   "id": "7036857bd1fa8ab7",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train the model",
   "id": "fa1ceb3eda454325"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T05:07:27.383154Z",
     "start_time": "2025-03-15T05:07:27.380224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_dataset, num_epochs=3, learning_rate=2e-5, batch_size=8):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        correct_predictions = 0\n",
    "        with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids']\n",
    "                attention_mask = batch['attention_mask']\n",
    "                labels = batch['labels']\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "                pbar.set_postfix(loss=epoch_loss/len(train_loader), accuracy=correct_predictions.double()/len(train_loader.dataset))\n",
    "                pbar.update(1)\n",
    "\n",
    "    torch.save(model.state_dict(), 'saved_models/bert_model.pt')\n",
    "    print('Model saved to saved_models/bert_model.pt')\n"
   ],
   "id": "5d99c7a3661ac68f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the model",
   "id": "156e96000fc9cf5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T05:07:27.674978Z",
     "start_time": "2025-03-15T05:07:27.672349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, test_dataset):\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    accuracy = correct_predictions.double() / len(test_loader.dataset)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n"
   ],
   "id": "115aeec4d389961e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize and train the model",
   "id": "531fa63523d9816"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:49:56.057625Z",
     "start_time": "2025-03-15T05:07:27.944902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "model = NewsClassifier(n_classes=num_classes)\n",
    "train_model(model, train_dataset, num_epochs=3, learning_rate=2e-5, batch_size=8)"
   ],
   "id": "df05adbe6506af9e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 445/445 [35:51<00:00,  4.84s/batch, accuracy=tensor(0.9236, dtype=torch.float64), loss=0.281] \n",
      "Epoch 2/3: 100%|██████████| 445/445 [33:39<00:00,  4.54s/batch, accuracy=tensor(0.9857, dtype=torch.float64), loss=0.0563] \n",
      "Epoch 3/3: 100%|██████████| 445/445 [32:55<00:00,  4.44s/batch, accuracy=tensor(0.9944, dtype=torch.float64), loss=0.0207] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to saved_models/news_classifier_model.pt\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the model",
   "id": "5206e7632073a8e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T06:51:49.877052Z",
     "start_time": "2025-03-15T06:49:56.677313Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate_model(model, test_dataset)",
   "id": "81017090f0b2f9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.09%\n",
      "Precision: 0.9815\n",
      "Recall: 0.9809\n",
      "F1 Score: 0.9809\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
